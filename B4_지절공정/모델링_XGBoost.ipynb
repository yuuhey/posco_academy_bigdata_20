{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7bdfa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#패키지 불러오기\n",
    "import pandas as pd # 데이터 처리\n",
    "import numpy as np #연산\n",
    "import matplotlib #시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import seaborn as sns\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split # 데이터 분할 : train, test\n",
    "from statsmodels.formula.api import ols # 회귀분석\n",
    "from statsmodels.api import qqplot, add_constant #회귀분석 상수항 추가\n",
    "import statsmodels.formula.api as smf # 회귀분석\n",
    "from sklearn.tree import DecisionTreeRegressor # 예측/회귀 Decision Tree\n",
    "from sklearn.ensemble import RandomForestRegressor #예측/회귀\n",
    "from sklearn.ensemble import GradientBoostingRegressor #예측/회귀\n",
    "from sklearn.linear_model import LinearRegression #분산 팽창계수 계산할때 사용\n",
    "from sklearn.feature_selection import RFE #후진제거법(변수선택)\n",
    "from sklearn.preprocessing import StandardScaler #표준화 회귀계수 산출(scale 변환)\n",
    "from statsmodels.tools.eval_measures import rmse # 평가함수\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import tree\n",
    "import xgboost as xgb ## XGBoost 불러오기\n",
    "from xgboost import plot_importance\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor #다중공산성 확인\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "import graphviz # 나무구조 시각화\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import datetime\n",
    "\n",
    "#로지스틱 회귀\n",
    "from statsmodels.api import Logit\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# 분류 SVM\n",
    "from sklearn.svm import SVC\n",
    "# 분류 NN (MLPClassifier)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# 분류 KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# 최적 모델, 파라미터 탐색\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "#import pyreadr\n",
    "import seaborn as sns\n",
    "import multiprocessing as mp\n",
    "from glob import glob\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "# 메트릭 라이브러리\n",
    "from sklearn.metrics import accuracy_score, plot_roc_curve, precision_score, recall_score\n",
    "\n",
    "# 한글을 지원하는 폰트로 변경\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'  # 윈도우는 'Malgun Gothic'으로 변경 요망\n",
    "\n",
    "# plot style을 ggplot으로 변경\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# 모든 것을 출력하는 옵션\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "def make_line(df, tagname):\n",
    "    df = df[(df['id'] == tagname) & (df['cause'] != '기타중지')]\n",
    "    df = df.sort_values('datetime').reset_index()\n",
    "    \n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.lineplot(x='index',y='value',hue='cause',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f826fd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('오대오.csv')\n",
    "#df_raw_3['datetime'] = pd.to_datetime(df_raw_3.datetime).dt.tz_localize(None)\n",
    "#df_raw_3 = pd.pivot_table(df_raw_3, index ='datetime', columns = 'id', values ='value')\n",
    "#df_raw_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90dca061",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = df_raw.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "233c5290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TAG_001</th>\n",
       "      <th>TAG_002</th>\n",
       "      <th>TAG_004</th>\n",
       "      <th>TAG_005</th>\n",
       "      <th>TAG_006</th>\n",
       "      <th>TAG_007</th>\n",
       "      <th>TAG_008</th>\n",
       "      <th>TAG_011</th>\n",
       "      <th>TAG_012</th>\n",
       "      <th>TAG_013</th>\n",
       "      <th>...</th>\n",
       "      <th>TAG_185</th>\n",
       "      <th>TAG_186</th>\n",
       "      <th>TAG_187</th>\n",
       "      <th>TAG_188</th>\n",
       "      <th>TAG_189</th>\n",
       "      <th>TAG_190</th>\n",
       "      <th>TAG_191</th>\n",
       "      <th>TAG_192</th>\n",
       "      <th>TAG_193</th>\n",
       "      <th>cause</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.516590</td>\n",
       "      <td>3.727272</td>\n",
       "      <td>3.659474</td>\n",
       "      <td>64.386761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.879403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>91.126781</td>\n",
       "      <td>43.569761</td>\n",
       "      <td>...</td>\n",
       "      <td>40.107615</td>\n",
       "      <td>39.866318</td>\n",
       "      <td>39.867307</td>\n",
       "      <td>39.242749</td>\n",
       "      <td>0.045077</td>\n",
       "      <td>0.338026</td>\n",
       "      <td>0.199523</td>\n",
       "      <td>0.003820</td>\n",
       "      <td>46.439539</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.438721</td>\n",
       "      <td>3.863102</td>\n",
       "      <td>3.823411</td>\n",
       "      <td>0.370337</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>92.520378</td>\n",
       "      <td>52.853971</td>\n",
       "      <td>...</td>\n",
       "      <td>40.061705</td>\n",
       "      <td>29.150599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.549413</td>\n",
       "      <td>0.060481</td>\n",
       "      <td>0.313373</td>\n",
       "      <td>0.098486</td>\n",
       "      <td>0.035789</td>\n",
       "      <td>94.234855</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.369410</td>\n",
       "      <td>3.819573</td>\n",
       "      <td>3.849695</td>\n",
       "      <td>122.368513</td>\n",
       "      <td>27.823089</td>\n",
       "      <td>0.096102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>92.611488</td>\n",
       "      <td>51.192340</td>\n",
       "      <td>...</td>\n",
       "      <td>39.910447</td>\n",
       "      <td>40.206674</td>\n",
       "      <td>40.657971</td>\n",
       "      <td>40.766664</td>\n",
       "      <td>0.489483</td>\n",
       "      <td>0.178890</td>\n",
       "      <td>0.051197</td>\n",
       "      <td>0.035789</td>\n",
       "      <td>64.669526</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.080565</td>\n",
       "      <td>3.913643</td>\n",
       "      <td>3.882729</td>\n",
       "      <td>227.436914</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.740705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>90.915691</td>\n",
       "      <td>48.961057</td>\n",
       "      <td>...</td>\n",
       "      <td>33.887585</td>\n",
       "      <td>40.356547</td>\n",
       "      <td>39.592079</td>\n",
       "      <td>40.202029</td>\n",
       "      <td>0.264244</td>\n",
       "      <td>0.228764</td>\n",
       "      <td>0.009547</td>\n",
       "      <td>0.029205</td>\n",
       "      <td>48.615663</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.344228</td>\n",
       "      <td>3.676193</td>\n",
       "      <td>3.674700</td>\n",
       "      <td>76.245618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.329847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>92.037182</td>\n",
       "      <td>48.874683</td>\n",
       "      <td>...</td>\n",
       "      <td>40.347095</td>\n",
       "      <td>40.627034</td>\n",
       "      <td>39.046095</td>\n",
       "      <td>39.954925</td>\n",
       "      <td>0.193447</td>\n",
       "      <td>0.410250</td>\n",
       "      <td>0.027081</td>\n",
       "      <td>0.087180</td>\n",
       "      <td>49.166320</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109435</th>\n",
       "      <td>14.664333</td>\n",
       "      <td>3.582974</td>\n",
       "      <td>3.536546</td>\n",
       "      <td>67.188139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>91.572893</td>\n",
       "      <td>49.440436</td>\n",
       "      <td>...</td>\n",
       "      <td>38.212043</td>\n",
       "      <td>35.510047</td>\n",
       "      <td>38.788630</td>\n",
       "      <td>40.738352</td>\n",
       "      <td>0.121573</td>\n",
       "      <td>0.195366</td>\n",
       "      <td>0.021214</td>\n",
       "      <td>0.097006</td>\n",
       "      <td>47.532919</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109436</th>\n",
       "      <td>14.252853</td>\n",
       "      <td>3.924505</td>\n",
       "      <td>3.894912</td>\n",
       "      <td>165.684886</td>\n",
       "      <td>5.189121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>91.273919</td>\n",
       "      <td>49.740476</td>\n",
       "      <td>...</td>\n",
       "      <td>39.948361</td>\n",
       "      <td>41.142189</td>\n",
       "      <td>40.687020</td>\n",
       "      <td>39.954327</td>\n",
       "      <td>0.061273</td>\n",
       "      <td>0.201190</td>\n",
       "      <td>0.121320</td>\n",
       "      <td>0.077722</td>\n",
       "      <td>34.597847</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109437</th>\n",
       "      <td>14.730582</td>\n",
       "      <td>3.548382</td>\n",
       "      <td>3.516528</td>\n",
       "      <td>27.604100</td>\n",
       "      <td>2.630102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>91.385959</td>\n",
       "      <td>50.079478</td>\n",
       "      <td>...</td>\n",
       "      <td>39.606370</td>\n",
       "      <td>40.273973</td>\n",
       "      <td>40.311136</td>\n",
       "      <td>36.640596</td>\n",
       "      <td>0.345311</td>\n",
       "      <td>0.277868</td>\n",
       "      <td>0.044777</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>78.200642</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109438</th>\n",
       "      <td>14.223682</td>\n",
       "      <td>3.595405</td>\n",
       "      <td>3.693201</td>\n",
       "      <td>210.320778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.981309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>90.416878</td>\n",
       "      <td>51.816844</td>\n",
       "      <td>...</td>\n",
       "      <td>2.718306</td>\n",
       "      <td>40.355379</td>\n",
       "      <td>14.064412</td>\n",
       "      <td>40.099579</td>\n",
       "      <td>0.136705</td>\n",
       "      <td>0.257537</td>\n",
       "      <td>0.004777</td>\n",
       "      <td>0.041058</td>\n",
       "      <td>30.884150</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109439</th>\n",
       "      <td>14.554677</td>\n",
       "      <td>3.753547</td>\n",
       "      <td>3.727098</td>\n",
       "      <td>82.000093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.285845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>92.530532</td>\n",
       "      <td>51.148107</td>\n",
       "      <td>...</td>\n",
       "      <td>37.448828</td>\n",
       "      <td>58.308463</td>\n",
       "      <td>39.529865</td>\n",
       "      <td>43.157938</td>\n",
       "      <td>0.087284</td>\n",
       "      <td>0.285926</td>\n",
       "      <td>0.054501</td>\n",
       "      <td>0.082676</td>\n",
       "      <td>67.736807</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109440 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          TAG_001   TAG_002   TAG_004     TAG_005    TAG_006    TAG_007  \\\n",
       "0       14.516590  3.727272  3.659474   64.386761   0.000000  10.879403   \n",
       "1       14.438721  3.863102  3.823411    0.370337   0.000000   0.019885   \n",
       "2       14.369410  3.819573  3.849695  122.368513  27.823089   0.096102   \n",
       "3       14.080565  3.913643  3.882729  227.436914   0.000000  35.740705   \n",
       "4       14.344228  3.676193  3.674700   76.245618   0.000000  12.329847   \n",
       "...           ...       ...       ...         ...        ...        ...   \n",
       "109435  14.664333  3.582974  3.536546   67.188139   0.000000   0.000000   \n",
       "109436  14.252853  3.924505  3.894912  165.684886   5.189121   0.000000   \n",
       "109437  14.730582  3.548382  3.516528   27.604100   2.630102   0.000000   \n",
       "109438  14.223682  3.595405  3.693201  210.320778   0.000000  37.981309   \n",
       "109439  14.554677  3.753547  3.727098   82.000093   0.000000  15.285845   \n",
       "\n",
       "        TAG_008  TAG_011    TAG_012    TAG_013  ...    TAG_185    TAG_186  \\\n",
       "0           0.0    100.0  91.126781  43.569761  ...  40.107615  39.866318   \n",
       "1           0.0    100.0  92.520378  52.853971  ...  40.061705  29.150599   \n",
       "2           0.0    100.0  92.611488  51.192340  ...  39.910447  40.206674   \n",
       "3           0.0    100.0  90.915691  48.961057  ...  33.887585  40.356547   \n",
       "4           0.0    100.0  92.037182  48.874683  ...  40.347095  40.627034   \n",
       "...         ...      ...        ...        ...  ...        ...        ...   \n",
       "109435      0.0    100.0  91.572893  49.440436  ...  38.212043  35.510047   \n",
       "109436      0.0    100.0  91.273919  49.740476  ...  39.948361  41.142189   \n",
       "109437      0.0    100.0  91.385959  50.079478  ...  39.606370  40.273973   \n",
       "109438      0.0    100.0  90.416878  51.816844  ...   2.718306  40.355379   \n",
       "109439      0.0    100.0  92.530532  51.148107  ...  37.448828  58.308463   \n",
       "\n",
       "          TAG_187    TAG_188   TAG_189   TAG_190   TAG_191   TAG_192  \\\n",
       "0       39.867307  39.242749  0.045077  0.338026  0.199523  0.003820   \n",
       "1        0.000000  39.549413  0.060481  0.313373  0.098486  0.035789   \n",
       "2       40.657971  40.766664  0.489483  0.178890  0.051197  0.035789   \n",
       "3       39.592079  40.202029  0.264244  0.228764  0.009547  0.029205   \n",
       "4       39.046095  39.954925  0.193447  0.410250  0.027081  0.087180   \n",
       "...           ...        ...       ...       ...       ...       ...   \n",
       "109435  38.788630  40.738352  0.121573  0.195366  0.021214  0.097006   \n",
       "109436  40.687020  39.954327  0.061273  0.201190  0.121320  0.077722   \n",
       "109437  40.311136  36.640596  0.345311  0.277868  0.044777  0.000000   \n",
       "109438  14.064412  40.099579  0.136705  0.257537  0.004777  0.041058   \n",
       "109439  39.529865  43.157938  0.087284  0.285926  0.054501  0.082676   \n",
       "\n",
       "          TAG_193  cause  \n",
       "0       46.439539      0  \n",
       "1       94.234855      0  \n",
       "2       64.669526      0  \n",
       "3       48.615663      0  \n",
       "4       49.166320      0  \n",
       "...           ...    ...  \n",
       "109435  47.532919      1  \n",
       "109436  34.597847      1  \n",
       "109437  78.200642      1  \n",
       "109438  30.884150      1  \n",
       "109439  67.736807      1  \n",
       "\n",
       "[109440 rows x 140 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3b130c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TAG_001    0\n",
       "TAG_002    0\n",
       "TAG_004    0\n",
       "TAG_005    0\n",
       "TAG_006    0\n",
       "          ..\n",
       "TAG_190    0\n",
       "TAG_191    0\n",
       "TAG_192    0\n",
       "TAG_193    0\n",
       "cause      0\n",
       "Length: 140, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 빌드전 결측치 최종 확인\n",
    "df_raw.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d08396a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65664, 140)\n",
      "(43776, 140)\n"
     ]
    }
   ],
   "source": [
    "# split data\n",
    "train_data, test_data = train_test_split(df_raw, train_size = 0.6, random_state = 1234)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2ce3b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_y = 'cause'\n",
    "my_x = train_data.drop('cause', axis = 1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f96e42a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(data=train_data[my_x], label = train_data[my_y])\n",
    "dtest = xgb.DMatrix(data=test_data[my_x], label=test_data[my_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909281d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial,data=data,target=target):\n",
    "    global preds\n",
    "    global rmse\n",
    "    \n",
    "    \n",
    "    param = {\n",
    "        'tree_method':'gpu_hist',  # this parameter means using the GPU when training our model to speedup the training process\n",
    "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
    "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n",
    "        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', [0.008,0.01,0.012,0.014,0.016,0.018, 0.02]),\n",
    "        'n_estimators': 10000,\n",
    "        'max_depth': trial.suggest_categorical('max_depth', [5,7,9,11,13,15,17]),\n",
    "        'random_state': trial.suggest_categorical('random_state', [2020]),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
    "\n",
    "    }\n",
    "    model = xgb.XGBRegressor(**param)  \n",
    "    objective = 'reg:squarederror'\n",
    "    model.fit(X_train,y_train,eval_set=[(X_test,y_test)],early_stopping_rounds=100,verbose=False)\n",
    "    \n",
    "    preds = model.predict(X_test)\n",
    "    #val_score = accuracy_score(y_test, preds)\n",
    "    rmse = mean_squared_error(y_test, preds,squared=False)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b7d2aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "653ca368",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(tree_method = 'gpu_hist',n_estimators=500, learning_rate=0.2, max_depth=10, random_state = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbb5d792",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=0,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.2, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=10, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=500, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=1234, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=0,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.2, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=10, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=500, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=1234, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=0,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.2, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=10, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=500, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=1234, ...)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.fit(train_data[my_x],train_data[my_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "161be067",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_model.predict(test_data[my_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5984fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9961851242690059"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, test_data[my_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe7c14c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.000\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on training set: {:.3f}\".format(xgb_model.score(train_data[my_x],train_data[my_y])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4633c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.996\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test 데이터 셋 정확도\n",
    "print(\"Accuracy on test set: {:.3f}\\n\".format(xgb_model.score(test_data[my_x],test_data[my_y])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63c7009c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      "[[21719   147]\n",
      " [   20 21890]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "print(\"Confusion matrix: \\n{}\".format(confusion_matrix(test_data[my_y], y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d68e0ab1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99908   0.99328   0.99617     21866\n",
      "           1    0.99333   0.99909   0.99620     21910\n",
      "\n",
      "    accuracy                        0.99619     43776\n",
      "   macro avg    0.99620   0.99618   0.99619     43776\n",
      "weighted avg    0.99620   0.99619   0.99619     43776\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 목표변수의 빈도 불균형 : f1 score로 모델 평가 \n",
    "print(classification_report(test_data[my_y], y_pred, digits=5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
